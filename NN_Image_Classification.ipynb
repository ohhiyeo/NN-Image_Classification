{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "coVCAw9gMBbq"
      },
      "source": [
        "#########################################################################################\n",
        "#         BATCH_SIZE = 1:                                                               #\n",
        "#         Epoch   0 Time     40.8 lr = 0.000100 avg loss = 0.352032 accuracy = 90.70    # \n",
        "#         Epoch   1 Time     40.8 lr = 0.003400 avg loss = 0.201859 accuracy = 94.94    #\n",
        "#         Epoch   2 Time     40.6 lr = 0.006700 avg loss = 0.125801 accuracy = 95.78    #\n",
        "#         Epoch   3 Time     40.6 lr = 0.010000 avg loss = 0.098636 accuracy = 95.21    #\n",
        "#         Epoch   4 Time     40.8 lr = 0.009699 avg loss = 0.069400 accuracy = 96.73    #\n",
        "#         Epoch   5 Time     40.6 lr = 0.008831 avg loss = 0.050098 accuracy = 96.99    #\n",
        "#         Epoch   6 Time     40.8 lr = 0.007502 avg loss = 0.035275 accuracy = 97.57    #\n",
        "#         Epoch   7 Time     40.6 lr = 0.005872 avg loss = 0.024438 accuracy = 97.52    #\n",
        "#         Epoch   8 Time     40.7 lr = 0.004138 avg loss = 0.016617 accuracy = 97.76    #\n",
        "#         Epoch   9 Time     40.6 lr = 0.002507 avg loss = 0.011746 accuracy = 98.00    #\n",
        "#         Epoch  10 Time     40.6 lr = 0.001178 avg loss = 0.009105 accuracy = 98.05    #\n",
        "#         Epoch  11 Time     40.6 lr = 0.000311 avg loss = 0.007955 accuracy = 98.05    #\n",
        "#         Epoch  12 Time     40.9 lr = 0.000010 avg loss = 0.007389 accuracy = 98.06    #\n",
        "#                                                                                       #\n",
        "#         BATCH_SIZE = 32:                                                              #\n",
        "#         Epoch   0 Time      6.5 lr = 0.000100 avg loss = 2.365506 accuracy =  6.26    #\n",
        "#         Epoch   1 Time      6.6 lr = 0.003400 avg loss = 2.340736 accuracy =  7.51    #\n",
        "#         Epoch   2 Time      6.5 lr = 0.006700 avg loss = 2.316888 accuracy = 10.47    #\n",
        "#         Epoch   3 Time      6.7 lr = 0.010000 avg loss = 2.286211 accuracy = 16.54    #\n",
        "#         Epoch   4 Time      6.6 lr = 0.009699 avg loss = 2.247941 accuracy = 22.72    #\n",
        "#         Epoch   5 Time      6.5 lr = 0.008831 avg loss = 2.204488 accuracy = 29.74    #\n",
        "#         Epoch   6 Time      6.5 lr = 0.007502 avg loss = 2.154590 accuracy = 35.92    #\n",
        "#         Epoch   7 Time      6.4 lr = 0.005872 avg loss = 2.100983 accuracy = 40.18    #\n",
        "#         Epoch   8 Time      6.6 lr = 0.004138 avg loss = 2.050878 accuracy = 43.26    #\n",
        "#         Epoch   9 Time      6.4 lr = 0.002507 avg loss = 2.011913 accuracy = 44.79    #\n",
        "#         Epoch  10 Time      6.6 lr = 0.001179 avg loss = 1.987894 accuracy = 45.97    #\n",
        "#         Epoch  11 Time      6.4 lr = 0.000311 avg loss = 1.977104 accuracy = 46.31    #\n",
        "#         Epoch  12 Time      6.6 lr = 0.000010 avg loss = 1.974445 accuracy = 46.33    #\n",
        "#                                                                                       #\n",
        "#         BATCH_SIZE = 128:                                                             #\n",
        "#         Epoch   0 Time      5.9 lr = 0.000100 avg loss = 2.371592 accuracy =  6.73    #\n",
        "#         Epoch   1 Time      6.0 lr = 0.003400 avg loss = 2.353004 accuracy =  6.45    #\n",
        "#         Epoch   2 Time      5.8 lr = 0.006700 avg loss = 2.339738 accuracy =  6.65    #\n",
        "#         Epoch   3 Time      5.7 lr = 0.010000 avg loss = 2.336695 accuracy =  6.92    #\n",
        "#         Epoch   4 Time      6.5 lr = 0.009699 avg loss = 2.334418 accuracy =  7.18    #\n",
        "#         Epoch   5 Time      7.8 lr = 0.008831 avg loss = 2.332328 accuracy =  7.39    #\n",
        "#         Epoch   6 Time      5.7 lr = 0.007502 avg loss = 2.330570 accuracy =  7.43    #\n",
        "#         Epoch   7 Time      5.8 lr = 0.005872 avg loss = 2.329191 accuracy =  7.63    #\n",
        "#         Epoch   8 Time      5.7 lr = 0.004138 avg loss = 2.328188 accuracy =  7.77    #\n",
        "#         Epoch   9 Time      5.8 lr = 0.002507 avg loss = 2.327525 accuracy =  7.80    #\n",
        "#         Epoch  10 Time      5.7 lr = 0.001179 avg loss = 2.327147 accuracy =  7.80    #\n",
        "#         Epoch  11 Time      5.7 lr = 0.000311 avg loss = 2.326978 accuracy =  7.84    #\n",
        "#         Epoch  12 Time      5.9 lr = 0.000010 avg loss = 2.326935 accuracy =  7.83    #\n",
        "#                                                                                       #\n",
        "#########################################################################################\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZk7kOresJWd"
      },
      "source": [
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import time\n",
        "import math\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl2SrC7_sJ8Z"
      },
      "source": [
        "# data\n",
        "DATA_NUM_TRAIN         = 60000\n",
        "DATA_NUM_TEST          = 10000\n",
        "DATA_CHANNELS          = 1\n",
        "DATA_ROWS              = 28\n",
        "DATA_COLS              = 28\n",
        "DATA_CLASSES           = 10\n",
        "DATA_NORM              = np.float32(255.0)\n",
        "DATA_URL_TRAIN_DATA    = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS  = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA     = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS   = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA   = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA    = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS  = 'test_labels.gz'\n",
        "BATCH_SIZE = 1\n",
        "REGULARIZATION = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH7PSyG5sKUS"
      },
      "source": [
        "# model\n",
        "MODEL_N0 = DATA_ROWS*DATA_COLS\n",
        "MODEL_N1 = 100\n",
        "MODEL_N2 = 100\n",
        "MODEL_N3 = DATA_CLASSES\n",
        "TOTAL_LAYER = 4\n",
        "HIDDEN_LAYER = 3 #Last layer is the softmax, 4-3 = 1 is the first layer which is the input"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmM9J4hssKzS"
      },
      "source": [
        "# training\n",
        "TRAIN_LR_MAX          = 0.01\n",
        "TRAIN_LR_INIT_SCALE   = 0.01\n",
        "TRAIN_LR_FINAL_SCALE  = 0.001\n",
        "TRAIN_LR_INIT_EPOCHS  = 3\n",
        "TRAIN_LR_FINAL_EPOCHS = 10\n",
        "TRAIN_NUM_EPOCHS      = TRAIN_LR_INIT_EPOCHS + TRAIN_LR_FINAL_EPOCHS\n",
        "TRAIN_LR_INIT         = TRAIN_LR_MAX*TRAIN_LR_INIT_SCALE\n",
        "TRAIN_LR_FINAL        = TRAIN_LR_MAX*TRAIN_LR_FINAL_SCALE"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCzzFWOisWga"
      },
      "source": [
        "# display\n",
        "DISPLAY_ROWS   = 8\n",
        "DISPLAY_COLS   = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM    = DISPLAY_ROWS*DISPLAY_COLS"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_5RJcTP-ljg"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# DATA                                                                          #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# download data\n",
        "# opener = urllib.request.URLopener()\n",
        "# opener.addheader('User-Agent', 'Mozilla/5.0')\n",
        "# if (os.path.exists(DATA_FILE_TRAIN_DATA)   == False):\n",
        "#     opener.retrieve(DATA_URL_TRAIN_DATA,   DATA_FILE_TRAIN_DATA)\n",
        "# if (os.path.exists(DATA_FILE_TRAIN_LABELS) == False):\n",
        "#     opener.retrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "# if (os.path.exists(DATA_FILE_TEST_DATA)    == False):\n",
        "#     opener.retrieve(DATA_URL_TEST_DATA,    DATA_FILE_TEST_DATA)\n",
        "# if (os.path.exists(DATA_FILE_TEST_LABELS)  == False):\n",
        "#     opener.retrieve(DATA_URL_TEST_LABELS,  DATA_FILE_TEST_LABELS)\n",
        "\n",
        "files.upload()  \n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data   = gzip.open(\"/content/train_data.gz\", 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN*DATA_ROWS*DATA_COLS)\n",
        "train_data        = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data        = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels   = gzip.open(\"/content/train_labels.gz\", 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels        = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data   = gzip.open(\"/content/test_data.gz\", 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST*DATA_ROWS*DATA_COLS)\n",
        "test_data        = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data        = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels   = gzip.open(\"/content/test_labels.gz\", 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels        = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# debug\n",
        "# print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "# train_data is a sparse matrix\n",
        "# reshape function flattens 1*28*28 to a 1\n",
        "# print(np.reshape(train_data[1,:,:,:],MODEL_N0)/DATA_NORM)\n",
        "# print(train_data[2,:, :, :])\n",
        "# print(type(train_data))\n",
        "print(train_labels.shape[0]) # (60000,)\n",
        "print(train_labels)\n",
        "# print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "# print(test_labels.shape)  # (10000,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmTez-yq_mJB"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# DATA LOADER                                                                   #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# data loader class\n",
        "class DataLoader:\n",
        "\n",
        "    # save images x, labels y and data normalization factor x_norm\n",
        "    def __init__(self, x, y, x_norm):\n",
        "      self.x = x\n",
        "      self.y = y\n",
        "      self.x_norm = x_norm\n",
        "        \n",
        "    # return normalized image t and label t\n",
        "    def get(self, t, normalize = False):\n",
        "      image = np.reshape(self.x[t, :, :, :], MODEL_N0)/DATA_NORM\n",
        "      if normalize == True:\n",
        "        mu = image[np.nonzero(image)].mean()\n",
        "        v = image[np.nonzero(image)].var()\n",
        "        nz = image != 0.0\n",
        "        image[nz] = (image[nz]-mu)/v     \n",
        "      label = self.y[t]\n",
        "      return image, label\n",
        "       \n",
        "    # return the total number of images\n",
        "    def num(self):\n",
        "      return self.y.shape[0]\n",
        "# data loaders\n",
        "data_loader_train = DataLoader(train_data, train_labels, DATA_NORM)\n",
        "data_loader_test  = DataLoader(test_data,  test_labels,  DATA_NORM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HLl1kx5_mAc"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# LAYERS                                                                        #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# vector matrix multiplication layer\n",
        "class VectorMatrixMultiplication:\n",
        "\n",
        "    # initialize input x, parameters h and parameter gradient de/dh\n",
        "    def __init__(self, x_channels, y_channels):\n",
        "      self.x = np.zeros(x_channels, dtype = np.float32)\n",
        "      self.w = np.sqrt(2/(x_channels + y_channels), dtype = np.float32)*np.random.standard_normal((x_channels, y_channels)).astype(np.float32)\n",
        "      self.dedh = np.zeros(y_channels, dtype = np.float32)\n",
        "\n",
        "    # save the input x and return y = f(x, h)\n",
        "    def forward(self, x):\n",
        "      self.x = x\n",
        "      return self.x.dot(self.w)\n",
        "      \n",
        "    # compute and save the parameter gradient de/dh and return the input gradient de/dx = de/dy * dy/dx\n",
        "    def backward(self, dedy):\n",
        "      self.dedh = np.outer(self.x, dedy)\n",
        "      return dedy.dot(self.w.T)\n",
        "\n",
        "\n",
        "\n",
        "# vector vector addition layer\n",
        "class VectorVectorAddition:\n",
        "\n",
        "    # initialize parameters h and parameter gradient de/dh\n",
        "    def __init__(self, x_channels):\n",
        "      self.w = np.zeros(x_channels, dtype = np.float32)\n",
        "      self.dedh = np.zeros(x_channels, dtype = np.float32)\n",
        "\n",
        "    # return y = f(x, h)\n",
        "    def forward(self, x):\n",
        "      return x + self.w\n",
        "\n",
        "    # compute and save the parameter gradient de/dh and return the input gradient de/dx = de/dy * dy/dx\n",
        "    def backward(self, dedy):\n",
        "      self.dedh = dedy\n",
        "      return np.copy(self.dedh)\n",
        "        \n",
        "\n",
        "# ReLU layer\n",
        "class ReLU:\n",
        "\n",
        "    # initialize input x\n",
        "    def __init__(self, x_channels):\n",
        "      self.x = np.zeros(x_channels, dtype = np.float32)\n",
        "\n",
        "    # save the input x and return y = f(x, h)\n",
        "    def forward(self, x):\n",
        "      self.x = x\n",
        "      return np.maximum(np.float32(0.0), self.x)\n",
        "\n",
        "    # return the input gradient de/dx = de/dy * dy/dx\n",
        "    def backward(self, dedy):\n",
        "      return np.minimum(np.float32(1.0), np.maximum(np.float32(0.0),self.x))*dedy\n",
        "\n",
        "\n",
        "# soft max cross entropy layer\n",
        "class SoftMaxCrossEntropy:\n",
        "\n",
        "    # initialize probability p and label\n",
        "    def __init__(self, y_channels):\n",
        "      self.p = np.zeros(y_channels, dtype = np.float32)\n",
        "      self.label = 0\n",
        "    \n",
        "    # save the label, compute and save the probability p and return e = f(label, y)\n",
        "    def forward(self, label, y):\n",
        "      self.label = label\n",
        "      z = np.exp(y)\n",
        "      self.p = z/np.sum(z)\n",
        "      e = -np.log(self.p[self.label])\n",
        "      #print(e.shape, e)\n",
        "      return e\n",
        "  \n",
        "    # compute and return the input gradient de/dx from the saved probability and label; e is not used\n",
        "    def backward(self, e):\n",
        "      dedy = np.copy(self.p)\n",
        "      dedy[self.label] = self.p[self.label]-np.float32(1.0)\n",
        "      return dedy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjwMFKaF_ls4"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# NETWORK                                                                       #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# network\n",
        "class Network:\n",
        "\n",
        "    # save the network description parameters and create all layers\n",
        "    def __init__(self, rows, cols, n0, n1, n2, n3, total):\n",
        "      self.rows = rows\n",
        "      self.cols = cols\n",
        " \n",
        "      self.n0 = n0\n",
        "      self.n1 = n1\n",
        "      self.n2 = n2\n",
        "      self.n3 = n3\n",
        "      self.h1 = VectorMatrixMultiplication(self.n0, self.n1)\n",
        "      self.h2 = VectorVectorAddition(self.n1)\n",
        "      self.h3 = ReLU(self.n1)\n",
        "      self.h4 = VectorMatrixMultiplication(self.n1, self.n2)\n",
        "      self.h5 = VectorVectorAddition(self.n2)    \n",
        "      self.h6 = ReLU(self.n2)\n",
        "      self.h7 = VectorMatrixMultiplication(self.n2, self.n3)    \n",
        "      self.h8 = VectorVectorAddition(self.n3)\n",
        "      #for i in range(total):\n",
        "     \n",
        "      \n",
        "    # connect layers forward functions together to map the input image to the network output\n",
        "    # return the network output\n",
        "    def forward(self, img):\n",
        "      y1 = self.h1.forward(img)\n",
        "      y2 = self.h2.forward(y1)\n",
        "      y3 = self.h3.forward(y2)\n",
        "      y4 = self.h4.forward(y3)\n",
        "      y5 = self.h5.forward(y4)\n",
        "      y6 = self.h6.forward(y5)\n",
        "      y7 = self.h7.forward(y6)\n",
        "      y8 = self.h8.forward(y7)\n",
        "      return y8\n",
        "\n",
        "      # input = img\n",
        "      # for i in range(3):\n",
        "      #   VM = VectorMatrixMultiplication(eval(\"self.n\"+str(i)),eval(\"self.n\"+str(i+1)))\n",
        "      #   dot = VM.forward(input)\n",
        "      #   VV = VectorVectorAddition(eval(\"self.n\"+str(i+1)))\n",
        "      #   addBias = VV.forward(dot)\n",
        "      #   if i == 2:\n",
        "      #     return addBias\n",
        "      #   else:\n",
        "      #     R = ReLU(eval(\"self.n\"+str(i+1)))\n",
        "      #     input = R.forward(addBias)\n",
        "\n",
        "    # connect layers backward functions together to map de/dy at the end of the network to de/dx at the beginning\n",
        "    # note that inside the backward functions de/dh is computed for all parameters\n",
        "    # optionally return de/dx (unused)\n",
        "    def backward(self, dedy):\n",
        "      dh8_dh7 = self.h8.backward(dedy)  #h8.backward():saved dL_dh8 for w8 in self.dedh and pass back dh8_dh7(dedx7)\n",
        "      dh7_dh6 = self.h7.backward(dh8_dh7) #h7.backward():saved dh8_dh7 for w7 in self.dedh and pass back dedx6\n",
        "      dh6_dh5 = self.h6.backward(dh7_dh6) #h6.backward(): pass back dedx5\n",
        "      dh5_dh4 = self.h5.backward(dh6_dh5) #h5.backward(): saved dh6_dh5 for w5 in self.dedh and pass back dedx4\n",
        "      dh4_dh3 = self.h4.backward(dh5_dh4)  #h4.backward(): saved dh5_dh4 for w4 in self.dedh and pass back dedx3\n",
        "      dh3_dh2 = self.h3.backward(dh4_dh3) #h3.backward(): pass back dedx2\n",
        "      dh2_dh1 = self.h2.backward(dh3_dh2) #h2.backward(): saved dh3_dh2 for w2 in self.dedh and pass back dedx1\n",
        "      self.h1.backward(dh2_dh1) #h1.backward():saved dh2_dh1 for w1 in self.dedh and pass back dedx0(which is useless)\n",
        " \n",
        "    # update all layers with trainable parameters via h = h - lr * de/dh\n",
        "    def update(self, lr, total_input_num, regular_penalty = 0):\n",
        "      self.h1.w = self.h1.w - lr*self.h1.dedh + (regular_penalty*self.h1.w)/total_input_num\n",
        "      self.h2.w = self.h2.w - lr*self.h2.dedh + (regular_penalty*np.sum(self.h2.w))/total_input_num\n",
        "      self.h4.w = self.h4.w - lr*self.h4.dedh + (regular_penalty*self.h4.w)/total_input_num\n",
        "      self.h5.w = self.h5.w - lr*self.h5.dedh + (regular_penalty*np.sum(self.h5.w))/total_input_num \n",
        "      self.h7.w = self.h7.w - lr*self.h7.dedh + (regular_penalty*self.h7.w)/total_input_num\n",
        "      self.h8.w = self.h8.w - lr*self.h8.dedh + (regular_penalty*np.sum(self.h8.w))/total_input_num \n",
        "      # self.h1.w = self.h1.w - lr*self.h1.dedh\n",
        "      # self.h2.w = self.h2.w - lr*self.h2.dedh \n",
        "      # self.h4.w = self.h4.w - lr*self.h4.dedh \n",
        "      # self.h5.w = self.h5.w - lr*self.h5.dedh \n",
        "      # self.h7.w = self.h7.w - lr*self.h7.dedh \n",
        "      # self.h8.w = self.h8.w - lr*self.h8.dedh\n",
        "      #(regular_penalty*self.h1.w)/total_input_num\n",
        "    # def l2_matrix (w, total_input_num, regular_penalty = 0):\n",
        "    #   w_o = (regular_penalty*w)/total_input_num\n",
        "    #   too_small = w_o < 1e-6\n",
        "    #   w_o[too_small] = 0\n",
        "    #   return w_o\n",
        "      \n",
        "\n",
        "# network\n",
        "network = Network(DATA_ROWS, DATA_COLS, MODEL_N0, MODEL_N1, MODEL_N2, MODEL_N3, TOTAL_LAYER)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASNOyf7P1l5k"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# ERROR                                                                         #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# error\n",
        "error = SoftMaxCrossEntropy(MODEL_N3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTI-GMZ31mrJ"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# UPDATE                                                                        #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "\n",
        "    # linear warmup\n",
        "    if epoch < TRAIN_LR_INIT_EPOCHS:\n",
        "        lr = (TRAIN_LR_MAX - TRAIN_LR_INIT)*(float(epoch)/TRAIN_LR_INIT_EPOCHS) + TRAIN_LR_INIT\n",
        "    # 1/2 wave cosine decay\n",
        "    else:\n",
        "        lr = TRAIN_LR_FINAL + 0.5*(TRAIN_LR_MAX - TRAIN_LR_FINAL)*(1.0 + math.cos(((float(epoch) - TRAIN_LR_INIT_EPOCHS)/(TRAIN_LR_FINAL_EPOCHS - 1.0))*math.pi))\n",
        "\n",
        "    return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRwE3rNF1ux2"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# TRAIN                                                                         #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# initialize the epoch\n",
        "start_epoch      = 0\n",
        "start_time_epoch = time.time()\n",
        "\n",
        "# initialize the display statistics\n",
        "epochs   = np.zeros(TRAIN_NUM_EPOCHS, dtype=np.int32)\n",
        "avg_loss = np.zeros(TRAIN_NUM_EPOCHS, dtype=np.float32)\n",
        "accuracy = np.zeros(TRAIN_NUM_EPOCHS, dtype=np.float32)\n",
        "\n",
        "# cycle through the epochs\n",
        "for epoch in range(start_epoch, TRAIN_NUM_EPOCHS):\n",
        "\n",
        "    # set the learning rate\n",
        "    lr = np.float32(lr_schedule(epoch))\n",
        "\n",
        "    # initialize the epoch statistics\n",
        "    training_loss   = 0.0\n",
        "    testing_correct = 0\n",
        "\n",
        "    # cycle through the training data\n",
        "    # print(data_loader_train.num()/BATCH_SIZE)\n",
        "    total_input_number = data_loader_train.num()\n",
        "    for t in range(0,total_input_number,BATCH_SIZE):\n",
        "      dedy = np.zeros(10, dtype = np.float32)\n",
        "      e = 0.0\n",
        "      if t+BATCH_SIZE > total_input_number:\n",
        "        batch_iter = total_input_number-t\n",
        "      else: batch_iter = BATCH_SIZE \n",
        "      for b in range(batch_iter):\n",
        "        # data\n",
        "        img, label = data_loader_train.get(t+b)\n",
        "        # dedy = np.zeros(10, dtype = np.float32)\n",
        "        # network forward pass, error forward pass, error backward pass and network backward pass\n",
        "        y    = network.forward(img)\n",
        "        e    += error.forward(label, y)      \n",
        "        dedy += error.backward(e)\n",
        "        #input()\n",
        "      dedx = network.backward(dedy/batch_iter)\n",
        "\n",
        "        # weight update\n",
        "      network.update(lr,total_input_number,REGULARIZATION)\n",
        "\n",
        "        # update statistics\n",
        "      training_loss = training_loss + e\n",
        "\n",
        "    # cycle through the testing data\n",
        "    for t in range(data_loader_test.num()):\n",
        "\n",
        "        # data\n",
        "        img, label = data_loader_test.get(t)\n",
        "\n",
        "        # network forward pass and prediction\n",
        "        y          = network.forward(img)\n",
        "        prediction = (np.argmax(y)).astype(np.int32)\n",
        "\n",
        "        # update statistics\n",
        "        if (label == prediction):\n",
        "            testing_correct = testing_correct + 1\n",
        "            \n",
        "    # epoch statistics\n",
        "    elapsed_time_epoch = time.time() - start_time_epoch\n",
        "    start_time_epoch   = time.time()\n",
        "    epochs[epoch]      = epoch\n",
        "    avg_loss[epoch]    = training_loss/data_loader_train.num()\n",
        "    accuracy[epoch]    = 100.0*testing_correct/data_loader_test.num()\n",
        "    print('Epoch {0:3d} Time {1:8.1f} lr = {2:8.6f} avg loss = {3:8.6f} accuracy = {4:5.2f}'.format(epoch, elapsed_time_epoch, lr, avg_loss[epoch], accuracy[epoch]), flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6YMm0TLLDwG"
      },
      "source": [
        "#################################################################################\n",
        "#                                                                               #\n",
        "# DISPLAY                                                                       #\n",
        "#                                                                               #\n",
        "#################################################################################\n",
        "\n",
        "# plot of loss and accuracy vs epoch\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.plot(epochs, avg_loss, color='red')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Avg loss', color='red')\n",
        "ax1.set_title('Avg Loss And Accuracy Vs Epoch')\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(epochs, accuracy, color='blue')\n",
        "ax2.set_ylabel('Accuracy %', color='blue')\n",
        "\n",
        "# initialize the display predictions\n",
        "predictions = np.zeros(DISPLAY_NUM, dtype=np.int32)\n",
        "\n",
        "# cycle through the display data\n",
        "for t in range(DISPLAY_NUM):\n",
        "\n",
        "    # data\n",
        "    img, label = data_loader_test.get(t)\n",
        "\n",
        "    # network forward pass and prediction\n",
        "    y              = network.forward(img)\n",
        "    predictions[t] = (np.argmax(y)).astype(np.int32)\n",
        "\n",
        "# plot of display examples\n",
        "fig = plt.figure(figsize=(DISPLAY_COL_IN, DISPLAY_ROW_IN))\n",
        "ax  = []\n",
        "for t in range(DISPLAY_NUM):\n",
        "    img, label = data_loader_test.get(t)\n",
        "    img        = img.reshape((DATA_ROWS, DATA_COLS))\n",
        "    ax.append(fig.add_subplot(DISPLAY_ROWS, DISPLAY_COLS, t + 1))\n",
        "    ax[-1].set_title('True: ' + str(label) + ' xNN: ' + str(predictions[t]))\n",
        "    plt.imshow(img, cmap='Greys')\n",
        "\n",
        "# show figures\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}